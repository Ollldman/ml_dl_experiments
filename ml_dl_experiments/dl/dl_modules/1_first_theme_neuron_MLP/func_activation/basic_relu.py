import numpy as np
from numpy.typing import ArrayLike, NDArray

def relu(x: ArrayLike)-> NDArray[np.float64]:
    """
    Вы увидите линейный рост для x>0 и ноль для x≤0.

    Плюсы: 
    
    Простая.

    Быстро вычисляется.

    Не имеет проблем с исчезающими градиентами.
    
    Способствует разрежённости активаций. Активации сосредотачиваются лишь в «интересующих» нейронах, и сеть учится выделять действительно важные признаки. В итоге часто улучшаются обобщающая способность и интерпретируемость внутреннего представления.

    Благодаря своей простоте и эффективности функция используется почти во всех современных нейронных сетях.
    
    Минусы:

    Возникает эффект «мёртвых» нейронов (англ. dead neurons) — для x≤0 градиент равен нулю. Нейрон навсегда перестаёт передавать сигнал из-за постоянного обнуления выхода.

    Не центрирована вокруг нуля.
    """
    x = np.asarray(x, dtype=np.float64)
    return np.maximum(0, x)