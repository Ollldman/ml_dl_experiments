# üéØ PyTorch –¢–µ–Ω–∑–æ—Ä–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏: —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—è–º

## üìê –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –≤ CV:
```
Images:    (B, C, H, W)  # Batch, Channels, Height, Width
Masks:     (B, H, W) –∏–ª–∏ (B, 1, H, W)
Features:  (B, C, H, W) ‚Üí (B, C) –ø–æ—Å–ª–µ pooling
```

## üîÑ –û—Å–Ω–æ–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π

### 1. **`permute()` - –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ—Å–µ–π**
```python
# –ò–∑ (B, C, H, W) –≤ (B, H, W, C) –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
img = torch.randn(4, 3, 256, 256)  # B, C, H, W
img_vis = img.permute(0, 2, 3, 1)   # B, H, W, C

# –î–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:
img_single = img[0]                  # (C, H, W)
img_vis_single = img_single.permute(1, 2, 0)  # (H, W, C)
```

### 2. **`view()` - –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º—ã (–±–µ–∑ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è)**
```python
# –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –≤ –≤–µ–∫—Ç–æ—Ä
features = torch.randn(4, 512, 8, 8)  # (B, C, H, W)
flattened = features.view(4, -1)      # (B, 512*8*8) = (4, 32768)

# –ò–∑ 1D –≤ 4D
vector = torch.randn(4, 512)
reshaped = vector.view(4, 512, 1, 1)  # (B, C, 1, 1) –¥–ª—è broadcast
```

### 3. **`reshape()` - –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º—ã (—Å –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)**
```python
# –ë–µ–∑–æ–ø–∞—Å–Ω–µ–µ —á–µ–º view()
tensor = torch.randn(4, 3, 256, 256)
reshaped = tensor.reshape(4, -1)  # (4, 196608)
back = reshaped.reshape(4, 3, 256, 256)
```

### 4. **`unsqueeze()` / `squeeze()` - –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ/—É–¥–∞–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏**
```python
# –î–æ–±–∞–≤–∏—Ç—å batch dimension
img = torch.randn(3, 256, 256)      # (C, H, W)
img_batch = img.unsqueeze(0)        # (1, C, H, W)

# –î–æ–±–∞–≤–∏—Ç—å channel dimension –¥–ª—è –º–∞—Å–æ–∫
mask = torch.randn(4, 256, 256)     # (B, H, W)
mask_channel = mask.unsqueeze(1)    # (B, 1, H, W)

# –£–¥–∞–ª–∏—Ç—å singleton dimensions
tensor = torch.randn(1, 3, 1, 256, 256)
clean = tensor.squeeze()            # (3, 256, 256) - —É–¥–∞–ª–∏—Ç –í–°–ï –µ–¥–∏–Ω–∏—á–Ω—ã–µ
clean_safe = tensor.squeeze(dim=0)  # (3, 1, 256, 256) - —Ç–æ–ª—å–∫–æ —É–∫–∞–∑–∞–Ω–Ω—É—é
```

## üñºÔ∏è –û–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏

### –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (matplotlib/OpenCV)
```python
import matplotlib.pyplot as plt
import torch
import numpy as np

def tensor_to_image(tensor):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ç–µ–Ω–∑–æ—Ä PyTorch –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è matplotlib
    Input: (C, H, W) –∏–ª–∏ (B, C, H, W)
    Output: (H, W, C) numpy array
    """
    if tensor.dim() == 4:  # batch
        tensor = tensor[0]  # –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π
    
    # Detach, move to CPU, convert to numpy
    img = tensor.detach().cpu()
    
    # Normalize –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if img.min() < 0 or img.max() > 1:
        img = (img - img.min()) / (img.max() - img.min())
    
    # Permute channels last
    if img.shape[0] == 3 or img.shape[0] == 1:  # CHW
        img = img.permute(1, 2, 0)
    
    return img.numpy()

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
img_tensor = torch.randn(1, 3, 256, 256)  # –º–æ–¥–µ–ª—å –≤—ã–¥–∞–µ—Ç
img_np = tensor_to_image(img_tensor)      # (256, 256, 3)
plt.imshow(img_np)
plt.show()
```

### –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è/–¥–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
```python
# ImageNet –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406])
IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225])

def normalize_imagenet(tensor):
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    # tensor: (B, C, H, W) –∏–ª–∏ (C, H, W)
    return (tensor - IMAGENET_MEAN.view(-1, 1, 1)) / IMAGENET_STD.view(-1, 1, 1)

def denormalize_imagenet(tensor):
    """–û–±—Ä–∞—Ç–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"""
    return tensor * IMAGENET_STD.view(-1, 1, 1) + IMAGENET_MEAN.view(-1, 1, 1)

# –ü—Ä–∏–º–µ—Ä
img = torch.rand(3, 256, 256)  # [0, 1]
normalized = normalize_imagenet(img)  # –¥–ª—è –º–æ–¥–µ–ª–∏
denormalized = denormalize_imagenet(normalized)  # –¥–ª—è –ø–æ–∫–∞–∑–∞
```

## üéØ –ü–æ–ª–µ–∑–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è CV

### 1. **Broadcast –æ–ø–µ—Ä–∞—Ü–∏–π**
```python
# –î–æ–±–∞–≤–∏—Ç—å –∫–∞–Ω–∞–ª –∫ –º–∞—Å–∫–µ
mask = torch.randn(4, 256, 256)  # (B, H, W)
mask_expanded = mask.unsqueeze(1)  # (B, 1, H, W)

# –£–º–Ω–æ–∂–µ–Ω–∏–µ mask –Ω–∞ image
image = torch.randn(4, 3, 256, 256)
masked_image = image * mask_expanded  # broadcast: (B, 3, H, W) * (B, 1, H, W)
```

### 2. **–ö–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è –ø–æ —Ä–∞–∑–Ω—ã–º –æ—Å—è–º**
```python
# Concat –ø–æ batch dimension
batch1 = torch.randn(2, 3, 256, 256)
batch2 = torch.randn(3, 3, 256, 256)
combined = torch.cat([batch1, batch2], dim=0)  # (5, 3, 256, 256)

# Concat –ø–æ channel dimension
rgb = torch.randn(4, 3, 256, 256)
depth = torch.randn(4, 1, 256, 256)
rgbd = torch.cat([rgb, depth], dim=1)  # (4, 4, 256, 256)

# Stack –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–π –æ—Å–∏
tensors = [torch.randn(256, 256) for _ in range(5)]
stacked = torch.stack(tensors, dim=0)  # (5, 256, 256)
```

### 3. **–°–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ (patch extraction)**
```python
def extract_patches(tensor, patch_size=64, stride=32):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ç—á–∏ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    Input: (B, C, H, W)
    Output: (B * n_patches, C, patch_size, patch_size)
    """
    B, C, H, W = tensor.shape
    patches = tensor.unfold(2, patch_size, stride).unfold(3, patch_size, stride)
    patches = patches.contiguous().view(B, C, -1, patch_size, patch_size)
    patches = patches.permute(0, 2, 1, 3, 4).contiguous().view(-1, C, patch_size, patch_size)
    return patches

# –û–±—Ä–∞—Ç–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è
def reconstruct_from_patches(patches, original_shape, patch_size=64, stride=32):
    B, C, H, W = original_shape
    n_patches_h = (H - patch_size) // stride + 1
    n_patches_w = (W - patch_size) // stride + 1
    
    patches = patches.view(B, n_patches_h * n_patches_w, C, patch_size, patch_size)
    # ... —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è (—Å–ª–æ–∂–Ω–µ–µ, –∑–∞–≤–∏—Å–∏—Ç –æ—Ç overlap)
```

## üìä –†–∞–±–æ—Ç–∞ —Å –±–∞—Ç—á–∞–º–∏

### 1. **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –∫ –∫–∞–∂–¥–æ–º—É —ç–ª–µ–º–µ–Ω—Ç—É –±–∞—Ç—á–∞**
```python
# –í–∞—Ä–∏–∞–Ω—Ç 1: Vectorized (–ª—É—á—à–µ)
def process_batch_vectorized(batch):
    """batch: (B, C, H, W)"""
    return batch * 2 + 1  # –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π broadcast

# –í–∞—Ä–∏–∞–Ω—Ç 2: –Ø–≤–Ω—ã–π loop (–∏–Ω–æ–≥–¥–∞ –Ω—É–∂–Ω–æ)
def process_batch_loop(batch):
    results = []
    for i in range(batch.size(0)):
        img = batch[i]  # (C, H, W)
        processed = some_function(img)  # —Ä–∞–±–æ—Ç–∞–µ—Ç —Å 3D
        results.append(processed)
    return torch.stack(results, dim=0)
```

### 2. **Batch-wise statistics**
```python
# –°—Ä–µ–¥–Ω–µ–µ –ø–æ –±–∞—Ç—á—É (–Ω–æ –Ω–µ –ø–æ spatial dimensions)
batch = torch.randn(8, 3, 256, 256)
mean_per_image = batch.mean(dim=(2, 3))  # (8, 3) - mean per channel per image
mean_per_batch = batch.mean(dim=0)       # (3, 256, 256) - mean batch

# Normalize –∫–∞–∂–¥—ã–π image –æ—Ç–¥–µ–ª—å–Ω–æ
def batch_instance_norm(batch):
    """Normalize –∫–∞–∂–¥—ã–π image –≤ –±–∞—Ç—á–µ –æ—Ç–¥–µ–ª—å–Ω–æ"""
    B, C, H, W = batch.shape
    batch_flat = batch.view(B, C, -1)  # (B, C, H*W)
    mean = batch_flat.mean(dim=2, keepdim=True)  # (B, C, 1)
    std = batch_flat.std(dim=2, keepdim=True)    # (B, C, 1)
    normalized = (batch_flat - mean) / (std + 1e-5)
    return normalized.view(B, C, H, W)
```

## üîß –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏

```python
def print_tensor_info(tensor, name="Tensor"):
    """–ü–µ—á–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ–Ω–∑–æ—Ä–µ"""
    print(f"{name}:")
    print(f"  Shape: {tuple(tensor.shape)}")
    print(f"  Dtype: {tensor.dtype}")
    print(f"  Device: {tensor.device}")
    print(f"  Min: {tensor.min():.4f}, Max: {tensor.max():.4f}")
    print(f"  Mean: {tensor.mean():.4f}, Std: {tensor.std():.4f}")
    print(f"  Requires grad: {tensor.requires_grad}")
    if tensor.dim() == 4:
        print(f"  Format: (B={tensor.shape[0]}, C={tensor.shape[1]}, H={tensor.shape[2]}, W={tensor.shape[3]})")
    print()

def check_nan_inf(tensor):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN/Inf –∑–Ω–∞—á–µ–Ω–∏—è"""
    nan_count = torch.isnan(tensor).sum().item()
    inf_count = torch.isinf(tensor).sum().item()
    if nan_count > 0 or inf_count > 0:
        print(f"‚ö†Ô∏è  Warning: {nan_count} NaN, {inf_count} Inf values")
        return False
    return True
```

## üöÄ –ë—ã—Å—Ç—Ä—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è (one-liners)

```python
# CHW ‚Üí HWC –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
vis = tensor.permute(1, 2, 0).cpu().numpy()

# –î–æ–±–∞–≤–∏—Ç—å batch dimension –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
if tensor.dim() == 3:
    tensor = tensor.unsqueeze(0)

# –£–¥–∞–ª–∏—Ç—å batch dimension –µ—Å–ª–∏ –æ–¥–∏–Ω —ç–ª–µ–º–µ–Ω—Ç
if tensor.shape[0] == 1:
    tensor = tensor.squeeze(0)

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è bool –º–∞—Å–∫–∏ –≤ float
mask = (tensor > 0.5).float()

# One-hot encoding –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
def to_onehot(mask, num_classes):
    """mask: (B, H, W) –∏–ª–∏ (H, W) —Å –∫–ª–∞—Å—Å–∞–º–∏ 0..num_classes-1"""
    if mask.dim() == 2:
        mask = mask.unsqueeze(0)
    B, H, W = mask.shape
    onehot = torch.zeros(B, num_classes, H, W, device=mask.device)
    onehot.scatter_(1, mask.long().unsqueeze(1), 1)
    return onehot

# Score to prediction
probs = torch.randn(4, 2, 256, 256)  # (B, C, H, W)
preds = probs.argmax(dim=1)  # (B, H, W) —Å –∫–ª–∞—Å—Å–∞–º–∏ 0 –∏–ª–∏ 1
```

## üìù –ß–µ–∫–∞–ª–∏—Å—Ç –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–¥–∞—á–µ–π –≤ –º–æ–¥–µ–ª—å

```python
def prepare_for_model(tensor, model):
    """
    –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–Ω–∑–æ—Ä–∞ –¥–ª—è –º–æ–¥–µ–ª–∏
    """
    # 1. –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
    if tensor.dim() == 3:
        tensor = tensor.unsqueeze(0)  # add batch dim
    
    # 2. –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π dtype (–æ–±—ã—á–Ω–æ float32)
    if tensor.dtype != torch.float32:
        tensor = tensor.float()
    
    # 3. –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π device
    if next(model.parameters()).device != tensor.device:
        tensor = tensor.to(next(model.parameters()).device)
    
    # 4. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
    if hasattr(model, 'mean') and hasattr(model, 'std'):
        tensor = (tensor - model.mean) / model.std
    
    # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–Ω–∞—á–µ–Ω–∏–π
    assert not torch.isnan(tensor).any(), "NaN in input"
    
    return tensor
```

## üé® –ü—Ä–∏–º–µ—Ä –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏

```python
def full_image_pipeline(image_path, model, device='cuda'):
    """
    –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: –∑–∞–≥—Ä—É–∑–∫–∞ ‚Üí –æ–±—Ä–∞–±–æ—Ç–∫–∞ ‚Üí –º–æ–¥–µ–ª—å ‚Üí –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    """
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ (OpenCV/PIL ‚Üí numpy)
    import cv2
    img_np = cv2.imread(image_path)  # (H, W, 3) BGR
    img_np = cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB)  # RGB
    
    # 2. Preprocessing
    img_np = cv2.resize(img_np, (256, 256))  # resize
    img_tensor = torch.from_numpy(img_np).float() / 255.0  # [0, 1]
    
    # 3. CHW —Ñ–æ—Ä–º–∞—Ç
    img_tensor = img_tensor.permute(2, 0, 1)  # (3, 256, 256)
    
    # 4. Batch dimension
    img_tensor = img_tensor.unsqueeze(0)  # (1, 3, 256, 256)
    
    # 5. Normalize
    img_tensor = normalize_imagenet(img_tensor)
    
    # 6. Device
    img_tensor = img_tensor.to(device)
    
    # 7. Inference
    with torch.no_grad():
        output = model(img_tensor)
    
    # 8. Postprocessing
    if output.dim() == 4 and output.shape[1] > 1:  # segmentation
        pred = output.argmax(dim=1)  # (1, H, W)
        pred = pred.squeeze(0)  # (H, W)
    else:
        pred = output
    
    # 9. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    fig, (ax1, ax2) = plt.subplots(1, 2)
    ax1.imshow(denormalize_imagenet(img_tensor[0]).permute(1, 2, 0).cpu())
    ax2.imshow(pred.cpu(), cmap='gray')
    
    return pred
```

## üí° –ì–ª–∞–≤–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞

1. **–í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ `.shape`** –ø–æ—Å–ª–µ —Å–ª–æ–∂–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
2. **`.permute()` –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–æ—Ä—è–¥–∫–∞ –æ—Å–µ–π**, –Ω–µ `view/reshape`
3. **`.unsqueeze(0)` –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è batch dimension**
4. **`.squeeze()` –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –µ–¥–∏–Ω–∏—á–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π**
5. **`detach().cpu().numpy()` –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ numpy**
6. **–ù–æ—Ä–º–∞–ª–∏–∑—É–π—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è** –∫–∞–∫ –æ–∂–∏–¥–∞–µ—Ç –º–æ–¥–µ–ª—å
7. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `.to(device)`** –∞ –Ω–µ `.cuda()/.cpu()` –Ω–∞–ø—Ä—è–º—É—é
8. **–ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ NaN/Inf** –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ—Ç–ª–∞–¥–∫–∏

---

**–ó–∞–ø–æ–º–Ω–∏—Ç–µ:** `(B, C, H, W)` ‚Üí **B**atch, **C**hannels, **H**eight, **W**idth  
–î–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: `permute(0, 2, 3, 1)` –∏–ª–∏ `permute(1, 2, 0)` –¥–ª—è single image